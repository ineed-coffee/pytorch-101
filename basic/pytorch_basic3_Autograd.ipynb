{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch basic3 : Autograd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2aGuGMuM+0xNTyM7NC9Jj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ineed-coffee/pytorch-101/blob/main/basic/pytorch_basic3_Autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44FGCEh4v4Wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca593ee5-2c56-4f6e-d199-bfc5481e75a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiQ9-DbCDIaS"
      },
      "source": [
        "### 연결된 그래픽 카드와 CUDA 버전 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr3PL2lFDJuz",
        "outputId": "aa3263c1-f056-4e73-df18-af56a0ff88e6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr 19 14:37:53 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    32W / 250W |    899MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qgni3piIDNWn",
        "outputId": "50b1ffe5-199d-4e06-e42e-650fe5a1d372"
      },
      "source": [
        "!nvcc -V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IJ89UX7DRrq"
      },
      "source": [
        "### torch, torchvision, torchtext, 버전 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFOgXy7BDSU2",
        "outputId": "c72dc1d4-2ce7-43d9-c01d-ac748020e9e1"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchtext\n",
        "\n",
        "print(f'torch version: {torch.__version__}')\n",
        "print(f'torchvision version: {torchvision.__version__}')\n",
        "print(f'torchtext version: {torchtext.__version__}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch version: 1.8.1+cu101\n",
            "torchvision version: 0.9.1+cu101\n",
            "torchtext version: 0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn1QyBGQDaUG"
      },
      "source": [
        "# Basic 3. Autograd  \n",
        "\n",
        "__Torch의 기본 자료형인 Tensor의 경우 연산이 이루어질때 그 기록 또한 누적되어 자동미분이 가능한 구조로 계산된다.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYecfGvfDfko",
        "outputId": "3adf15b7-3d8e-4879-b3d8-595a24c58474"
      },
      "source": [
        "# Tensor 자료형으로 사칙연산 해보기 (과정이 grad_fn 에 저장된다)\n",
        "x = torch.tensor(1.5, requires_grad=True)\n",
        "y = torch.tensor(3.5, requires_grad=True)\n",
        "z=y**2+x\n",
        "\n",
        "print('x:',x)\n",
        "print('y:',y)\n",
        "print('z:',z)\n",
        "print()\n",
        "\n",
        "# 자동미분 계산\n",
        "z.backward()\n",
        "\n",
        "# 각 변수에 할당될 기울기(Gradient)\n",
        "print(f\"x에 계산된 기울기: {x.grad}\")\n",
        "print(f\"y에 계산된 기울기: {y.grad}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: tensor(1.5000, requires_grad=True)\n",
            "y: tensor(3.5000, requires_grad=True)\n",
            "z: tensor(13.7500, grad_fn=<AddBackward0>)\n",
            "\n",
            "x에 계산된 기울기: 1.0\n",
            "y에 계산된 기울기: 7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d2-6ATFRgoC"
      },
      "source": [
        "__이때, Tensor의 .grad 속성은 처음 requires\\_grad=True 로 설정한 Leaf Tensor에 대해서만 가능하다. 연산 중간의 텐서에서는 참조 불가__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWxZN3SRSQmK",
        "outputId": "41db48a4-e247-45d3-ac5b-4ce6f533adaf"
      },
      "source": [
        "x = torch.tensor(1.5, requires_grad=True) # Leaf Tensor\n",
        "y=x*2+3\n",
        "z=y**2\n",
        "\n",
        "print('x:',x)\n",
        "print('y:',y)\n",
        "print('z:',z)\n",
        "print()\n",
        "\n",
        "# 자동미분 계산\n",
        "z.backward()\n",
        "\n",
        "# 각 변수에 할당될 기울기(Gradient)\n",
        "print(f\"x에 계산된 기울기: {x.grad}\")\n",
        "print(f\"y에 계산된 기울기: {y.grad}\") # Not a Leaf Tensor => Error!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: tensor(1.5000, requires_grad=True)\n",
            "y: tensor(6., grad_fn=<AddBackward0>)\n",
            "z: tensor(36., grad_fn=<PowBackward0>)\n",
            "\n",
            "x에 계산된 기울기: 24.0\n",
            "y에 계산된 기울기: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrqfXXP6Tagp"
      },
      "source": [
        "### 이러한 Autograd 특성으로부터 선형회귀 모델을 생성해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8whLIBGxTlRl",
        "outputId": "a8a2ef6f-1708-4382-be0f-7e9df42bfd2b"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# 학습 device 설정\n",
        "torch.manual_seed=1120 # 시드 고정(CPU)\n",
        "if torch.cuda.is_available():\n",
        "  device_='cuda'\n",
        "  torch.cuda.manual_seed_all(1120) # 시드 고정(GPU)\n",
        "else:\n",
        "  device_='cpu'\n",
        "device = torch.device(device_)\n",
        "\n",
        "# Set Conditions & Hyper-parameters\n",
        "dtype_=torch.float\n",
        "R,C = 500,3 # 500개 데이터 샘플 , 각 데이터는 3-dim\n",
        "epochs=10000\n",
        "learning_rate=1e-3\n",
        "\n",
        "# Generate data, initialize weights & bias\n",
        "x = torch.randn((R,C),device=device, dtype=dtype_)\n",
        "y=torch.tensor([(2*sum(i)+1).item() for i in x],device=device, dtype=dtype_).view(-1,1)  # 목표식 y=2*x+1\n",
        "\n",
        "w1 = torch.zeros((C,1),device=device, dtype=dtype_,requires_grad=True) # 학습할 가중치와 편향\n",
        "b1 = torch.zeros(1,device=device, dtype=dtype_,requires_grad=True)\n",
        "\n",
        "# Set Optimizer\n",
        "optimizer=optim.SGD([w1,b1],lr=learning_rate)\n",
        "\n",
        "# Train\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  y_hat=x.matmul(w1)+b1\n",
        "  cost=torch.mean((y-y_hat)**2) # Forward-pass\n",
        "\n",
        "  optimizer.zero_grad() # reset gradient to avoid accumulation\n",
        "  cost.backward()       # compute gradient of each parameter\n",
        "  optimizer.step()      # update each parameter\n",
        "\n",
        "  if not epoch%1000:\n",
        "    print(f'{epoch+1}/{epochs} : Cost={cost}')\n",
        "\n",
        "print(\"=\"*65)\n",
        "print(f'목표치: w1=(2,2,2) , b1=1')\n",
        "print(f'학습결과: w1={[v.item() for v in w1]} , b1={b1.item()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/10000 : Cost=14.351768493652344\n",
            "1001/10000 : Cost=0.17560093104839325\n",
            "2001/10000 : Cost=0.002341908635571599\n",
            "3001/10000 : Cost=3.5410659620538354e-05\n",
            "4001/10000 : Cost=6.201415203577199e-07\n",
            "5001/10000 : Cost=1.2345105382394195e-08\n",
            "6001/10000 : Cost=1.9163828302026786e-09\n",
            "7001/10000 : Cost=1.9163828302026786e-09\n",
            "8001/10000 : Cost=1.9163828302026786e-09\n",
            "9001/10000 : Cost=1.9163828302026786e-09\n",
            "=================================================================\n",
            "목표치: w1=(2,2,2) , b1=1\n",
            "학습결과: w1=[2.0, 1.9999690055847168, 1.999973177909851] , b1=0.9999855756759644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqslTGCzZjNC"
      },
      "source": [
        "### 어느정도 학습이 됐다면 테스트도 해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiYsJIYbi6Su",
        "outputId": "5157f48b-f26d-462f-aec3-e33b489253b8"
      },
      "source": [
        "test_in=torch.tensor([[1.,2.,4.]],device=device, dtype=dtype_) # 예상 정답은 2*(1+2+4)+1 = 15\n",
        "\n",
        "with torch.no_grad(): # gradient를 추적하지 않음을 의미\n",
        "  y_hat=test_in.matmul(w1)+b1\n",
        "  print(f\"예상 정답: {[(2*sum(i)+1).item() for i in test_in]}\")\n",
        "  print(f\"회귀식 예측 값: {y_hat}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예상 정답: [15.0]\n",
            "회귀식 예측 값: tensor([[14.9998]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}