{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch basic5 : modeling with 3 API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPa0o4MWNpA8qil/VfuwMD/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ineed-coffee/pytorch-101/blob/main/basic/pytorch_basic5_modeling_with_3_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14_15jz1Y5ci",
        "outputId": "21fc502d-3ec8-4b31-9dc4-740a7881ee00"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1lJAliTC-36"
      },
      "source": [
        "### 연결된 그래픽 카드와 CUDA 버전 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuew_O1NDW3M",
        "outputId": "b38a9432-6daa-40f5-86a8-dcb17a76da0d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 22 07:05:12 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN450VNkZ890",
        "outputId": "32cbd51a-a98f-4e66-c2aa-e85c2b513f58"
      },
      "source": [
        "!nvcc -V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRVQBTNmEvBx"
      },
      "source": [
        "### torch, torchvision, torchtext, 버전 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nv3d3ZCbYyp",
        "outputId": "7360e1ae-4c63-4972-d163-73350a9ec1d4"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchtext\n",
        "\n",
        "print(f'torch version: {torch.__version__}')\n",
        "print(f'torchvision version: {torchvision.__version__}')\n",
        "print(f'torchtext version: {torchtext.__version__}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch version: 1.8.1+cu101\n",
            "torchvision version: 0.9.1+cu101\n",
            "torchtext version: 0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cug6H17t5AJd"
      },
      "source": [
        "### Basic 5. 3-ways to build model from nn.Module  \n",
        "- Sequential API (easy, high-level)\n",
        "- Functional API (general way)\n",
        "- Subclassing API (pytorch standard)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FThEegoJ5BNe"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysu33Cm7YZLY"
      },
      "source": [
        "1. __Sequential API 방식. 간단한 모델을 설계하기에 최적__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8plmNdeV787Y",
        "outputId": "230c083d-2e0c-4cc8-e0d6-330bb74d6b77"
      },
      "source": [
        "# In: 20-dim -> hidden1: 100-unit -> hidden2: 100-unit -> Out: 10-dim 구조의 2계층 다중 분류 신경망 설계하기 \n",
        "\n",
        "model1 = nn.Sequential(\n",
        "    nn.Linear(20,30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,10),\n",
        "    nn.Softmax()\n",
        ")\n",
        "\n",
        "print(\"구성확인(default layer name): \")\n",
        "print(list(model1.modules()))\n",
        "\n",
        "# 각 layer에 이름을 부여하고자 한다면 다음과 같이 작성할 수 있다.\n",
        "model2 = nn.Sequential()\n",
        "model2.add_module(\"hidden1\",nn.Linear(20,30))\n",
        "model2.add_module(\"activation1\",nn.ReLU())\n",
        "model2.add_module(\"hidden2\",nn.Linear(30,10))\n",
        "model2.add_module(\"activation2\",nn.Softmax())\n",
        "\n",
        "print()\n",
        "print(\"=\"*65)\n",
        "print()\n",
        "\n",
        "print(\"구성확인(defined layer name): \")\n",
        "print(list(model2.modules()))\n",
        "print(\"접근 또한 가능, model2.hidden1\")\n",
        "print(model2.hidden1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "구성확인(default layer name): \n",
            "[Sequential(\n",
            "  (0): Linear(in_features=20, out_features=30, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=30, out_features=10, bias=True)\n",
            "  (3): Softmax(dim=None)\n",
            "), Linear(in_features=20, out_features=30, bias=True), ReLU(), Linear(in_features=30, out_features=10, bias=True), Softmax(dim=None)]\n",
            "\n",
            "=================================================================\n",
            "\n",
            "구성확인(defined layer name): \n",
            "[Sequential(\n",
            "  (hidden1): Linear(in_features=20, out_features=30, bias=True)\n",
            "  (activation1): ReLU()\n",
            "  (hidden2): Linear(in_features=30, out_features=10, bias=True)\n",
            "  (activation2): Softmax(dim=None)\n",
            "), Linear(in_features=20, out_features=30, bias=True), ReLU(), Linear(in_features=30, out_features=10, bias=True), Softmax(dim=None)]\n",
            "접근 또한 가능, model2.hidden1\n",
            "Linear(in_features=20, out_features=30, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CCPzuuLg3-U"
      },
      "source": [
        "2. __Functional API 방식. Sequential 방식으로는 설계가 까다로운 경우 활용. 가장 일반적인 방법__  \n",
        "- keras에서 이런 functional api 방식을 지원한다. Pytorch에서는 다음 방법인 subclassing api를 많이 씀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMkSDut0teDS",
        "outputId": "e8aa2541-2551-4916-bbd9-115a9ff45b73"
      },
      "source": [
        "from keras.layers import Input, Dense, concatenate\n",
        "from keras.models import Model\n",
        " \n",
        "# 두 종류의 입력이 있는 모델을 가정\n",
        "In_a = Input(shape=(28,))\n",
        "In_b = Input(shape=(64,))\n",
        " \n",
        "# In_a 에 대한 모듈 정의\n",
        "module1 = Dense(16, activation=\"relu\")(In_a)\n",
        "module1 = Dense(8, activation=\"relu\")(module1)\n",
        "module1 = Model(inputs=In_a, outputs=module1)\n",
        " \n",
        "# In_b 에 대한 모듈 정의\n",
        "module2 = Dense(64, activation=\"relu\")(In_b)\n",
        "module2 = Dense(32, activation=\"relu\")(module2)\n",
        "module2 = Dense(8, activation=\"relu\")(module2)\n",
        "module2 = Model(inputs=In_b, outputs=module2)\n",
        " \n",
        "# 두 모듈의 출력을 연결하는 층 생성(concatenate)\n",
        "concat_layer = concatenate([module1.output, module2.output])\n",
        " \n",
        "# 최종 단 정의\n",
        "top_layer = Dense(2, activation=\"relu\")(concat_layer)\n",
        "final = Dense(1, activation=\"linear\")(top_layer)\n",
        " \n",
        "# 최종 모델 정의\n",
        "model = Model(inputs=[module1.input, module2.input], outputs=final)\n",
        "\n",
        "# 모델 아키텍쳐 확인\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 28)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 64)           4160        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 16)           464         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 32)           2080        dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 8)            136         dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 8)            264         dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16)           0           dense_8[0][0]                    \n",
            "                                                                 dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 2)            34          concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 1)            3           dense_12[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 7,141\n",
            "Trainable params: 7,141\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8KWyMQOvFLi"
      },
      "source": [
        "3. __Subclassing API 방식. Pytorch 에서는 가장 standard 방식이며 객체형 프로그래밍 방식으로 구현한다.__  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfqFeRHZhKGs",
        "outputId": "9c5ba8b8-32b2-4303-da3c-80efb95d492f"
      },
      "source": [
        "# 직렬로 설계가 가능한 모듈형태의 layer의 경우 sequential 방식으로 작성하며 이들을 연결 시 Subclassing API 방식으로 작서하며 forward 메소드에 순전파 과정을 작성해주면 된다.\n",
        "class my_CNN(nn.Module):\n",
        "\n",
        "  def __init__(self,model_in,model_out):\n",
        "    super(my_CNN,self).__init__()\n",
        "\n",
        "    self.conv_idx=1\n",
        "    self.conv1=self._make_conv_module(model_in,32,3,1,1)\n",
        "    self.conv2=self._make_conv_module(32,64,3,1,1)\n",
        "    self.fc1  =nn.Linear(7*7*64,model_out)\n",
        "    nn.init.xavier_uniform_(self.fc1.weight)\n",
        "    self.classifier=nn.Softmax(dim=1)\n",
        "\n",
        "  def _make_conv_module(self,ch_in,ch_out,filter_size,stride,pad):\n",
        "    conv=nn.Sequential()\n",
        "    conv.add_module(f\"conv_{self.conv_idx}\",nn.Conv2d(ch_in,ch_out,kernel_size=filter_size,stride=stride,padding=pad))\n",
        "    conv.add_module(f\"relu_{self.conv_idx}\",nn.ReLU())\n",
        "    conv.add_module(f\"maxpool_{self.conv_idx}\",nn.MaxPool2d(2))\n",
        "    return conv\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    yhat=self.conv1(x)\n",
        "    yhat=self.conv2(yhat)\n",
        "    yhat=yhat.view(yhat.shape[0],-1)\n",
        "    yhat=self.fc1(yhat)\n",
        "    yhat=self.classifier(yhat)\n",
        "    return yhat\n",
        "\n",
        "model=my_CNN(3,10)\n",
        "print(model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_CNN(\n",
            "  (conv1): Sequential(\n",
            "    (conv_1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (relu_1): ReLU()\n",
            "    (maxpool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (relu_1): ReLU()\n",
            "    (maxpool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=3136, out_features=10, bias=True)\n",
            "  (classifier): Softmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}